{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 535845,
          "sourceType": "datasetVersion",
          "datasetId": 255093
        }
      ],
      "dockerImageVersionId": 29844,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from math import * # module math\n",
        "import matplotlib.pyplot as plt # visualization\n",
        "from PIL import Image\n",
        "import seaborn as sns # visualization\n",
        "import itertools\n",
        "import io\n",
        "import plotly.offline as py # visualization\n",
        "py.init_notebook_mode(connected=True) # visualization\n",
        "import plotly.graph_objs as go # visualization\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff # visualization\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": false,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-7EApRSzzUjM",
        "outputId": "34997f5e-1e43-44e6-f8c8-2f192ff7150f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "telcom = pd.read_csv(r\"churn-bigml-80.csv\")\n",
        "telcom_test = pd.read_csv(r\"churn-bigml-20.csv\")\n",
        "telcom.head()"
      ],
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "P1iRYYFYzUjN",
        "outputId": "777e76ca-b799-4b27-9f5d-422c889748f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3c978372a84b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtelcom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"../input/telecom-churn-datasets/churn-bigml-80.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtelcom_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"../input/telecom-churn-datasets/churn-bigml-20.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtelcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/telecom-churn-datasets/churn-bigml-80.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataoveriew(df, message):\n",
        "    print(f'{message}:\\n')\n",
        "    print(\"Rows:\", df.shape[0])\n",
        "    print(\"\\nNumber of features:\", df.shape[1])\n",
        "    print(\"\\nFeatures:\")\n",
        "    print(telcom.columns.tolist())\n",
        "    print(\"\\nMissing values:\", df.isnull().sum().values.sum())\n",
        "    print(\"\\nUnique values:\")\n",
        "    print(df.nunique())"
      ],
      "metadata": {
        "trusted": true,
        "id": "6C8UwsRkzUjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataoveriew(telcom, 'Overiew of the training dataset')"
      ],
      "metadata": {
        "trusted": true,
        "id": "-OzHk-jXzUjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataoveriew(telcom_test, 'Overiew of the test dataset')"
      ],
      "metadata": {
        "trusted": true,
        "id": "CMNi2fzHzUjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a id='2'>2. Exploratory Data Analysis</a>"
      ],
      "metadata": {
        "_uuid": "fbe477239c9240b5402053e0bc572bc5841c91a4",
        "id": "nJzMbpvpzUjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='2.1'>2.1. Customer churn in data</a>"
      ],
      "metadata": {
        "_uuid": "09ba96d314bd92da87f956c3b265b78317a17d17",
        "id": "K5jyOVjXzUjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trace = go.Pie(labels = telcom[\"Churn\"].value_counts().keys().tolist(),\n",
        "               values = telcom[\"Churn\"].value_counts().values.tolist(),\n",
        "               marker = dict(colors = ['royalblue','lime'],\n",
        "                             line = dict(color = \"white\", width =  1.3)\n",
        "                            ),\n",
        "               rotation = 90,\n",
        "               hoverinfo = \"label+value+text\",\n",
        "               hole = .5\n",
        "              )\n",
        "layout = go.Layout(dict(title = \"Customer churn in training data\",\n",
        "                        plot_bgcolor = \"rgb(243,243,243)\",\n",
        "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
        "                       )\n",
        "                  )\n",
        "data = [trace]\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "py.iplot(fig)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_uuid": "35bf6ff6c7e9ed36b0fb6fa2c67450a58135b62a",
        "trusted": true,
        "id": "UD6KVytozUjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='2.2'>2.2. Variable distributions</a>"
      ],
      "metadata": {
        "_uuid": "34b437d12b3391c3a4d6ae357cb23d408cbc1b18",
        "id": "m3eqYR49zUjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separating columns to be visualized\n",
        "out_cols = list(set(telcom.nunique()[telcom.nunique()<6].keys().tolist()\n",
        "                    + telcom.select_dtypes(include='object').columns.tolist()))\n",
        "viz_cols = [x for x in telcom.columns if x not in out_cols] + ['Churn']\n",
        "\n",
        "sns.pairplot(telcom[viz_cols], diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2hOtftfDzUjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a id='3'>3. Data preprocessing</a>"
      ],
      "metadata": {
        "_uuid": "6dfa77b43fe1a1a301bab65186c2a9f90245ab7d",
        "id": "_3ojkCqjzUjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Removing correlated and unneccessary columns\n",
        "col_to_drop = ['State', 'Area code', 'Total day charge', 'Total eve charge',\n",
        "               'Total night charge', 'Total intl charge']\n",
        "\n",
        "telcom = telcom.drop(columns = col_to_drop, axis = 1)\n",
        "telcom_test = telcom_test.drop(columns = col_to_drop, axis = 1)\n",
        "\n",
        "#target column\n",
        "target_col = [\"Churn\"]\n",
        "\n",
        "#number of levels in feature to be a categorical feature\n",
        "nlevels = 6\n",
        "\n",
        "#Separating categorical and numerical columns\n",
        "#categorical columns\n",
        "cat_cols = list(set(telcom.nunique()[telcom.nunique()<nlevels].keys().tolist()\n",
        "                    + telcom.select_dtypes(include='object').columns.tolist()))\n",
        "cat_cols = [x for x in cat_cols if x not in target_col]\n",
        "#numerical columns\n",
        "num_cols = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
        "#Binary columns with 2 values\n",
        "bin_cols = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
        "#Columns more than 2 values\n",
        "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
        "\n",
        "#Label encoding Binary columns\n",
        "le = LabelEncoder()\n",
        "for i in bin_cols:\n",
        "    telcom[i] = le.fit_transform(telcom[i])\n",
        "    telcom_test[i] = le.transform(telcom_test[i])\n",
        "\n",
        "#combining the train and test datasets\n",
        "trainsize = telcom.shape[0]\n",
        "comb = pd.concat((telcom, telcom_test), sort=False)\n",
        "\n",
        "#Duplicating columns for multi value columns\n",
        "comb = pd.get_dummies(data = comb, columns = multi_cols)\n",
        "\n",
        "#Separating the train and test datasets\n",
        "telcom = comb[:trainsize]\n",
        "telcom_test = comb[trainsize:]\n",
        "\n",
        "#Scaling Numerical columns\n",
        "std = StandardScaler()\n",
        "scaled = std.fit_transform(telcom[num_cols])\n",
        "scaled = pd.DataFrame(scaled, columns=num_cols)\n",
        "\n",
        "scaled_test = std.transform(telcom_test[num_cols])\n",
        "scaled_test = pd.DataFrame(scaled_test, columns=num_cols)\n",
        "\n",
        "#dropping original values merging scaled values for numerical columns\n",
        "df_telcom_og = telcom.copy()\n",
        "telcom = telcom.drop(columns = num_cols, axis = 1)\n",
        "telcom = telcom.merge(scaled, left_index=True, right_index=True, how = \"left\")\n",
        "\n",
        "df_telcom_test_og = telcom_test.copy()\n",
        "telcom_test = telcom_test.drop(columns = num_cols, axis = 1)\n",
        "telcom_test = telcom_test.merge(scaled_test, left_index=True, right_index=True, how = \"left\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "o-h4ze14zUjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='3.1'>3.1. Variable summary</a>"
      ],
      "metadata": {
        "_uuid": "9ec25cff71c0eb0f0c839a726cb06cb43462a53f",
        "id": "EwmpklcWzUjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = (df_telcom_og[[i for i in df_telcom_og.columns]].\n",
        "           describe().transpose().reset_index())\n",
        "\n",
        "summary = summary.rename(columns = {\"index\" : \"feature\"})\n",
        "summary = np.around(summary,3)\n",
        "\n",
        "val_lst = [summary['feature'], summary['count'],\n",
        "           summary['mean'],summary['std'],\n",
        "           summary['min'], summary['25%'],\n",
        "           summary['50%'], summary['75%'], summary['max']]\n",
        "\n",
        "trace  = go.Table(header = dict(values = summary.columns.tolist(),\n",
        "                                line = dict(color = ['#506784']),\n",
        "                                fill = dict(color = ['#119DFF']),\n",
        "                               ),\n",
        "                  cells  = dict(values = val_lst,\n",
        "                                line = dict(color = ['#506784']),\n",
        "                                fill = dict(color = [\"lightgrey\",'#F5F8FF'])\n",
        "                               ),\n",
        "                  columnwidth = [200,60,100,100,60,60,80,80,80])\n",
        "layout = go.Layout(dict(title = \"Training variable Summary\"))\n",
        "figure = go.Figure(data=[trace],layout=layout)\n",
        "py.iplot(figure)"
      ],
      "metadata": {
        "_uuid": "9f1fbaf6d979c28b6f763eb398e4cdd2091fc37b",
        "trusted": true,
        "id": "mI5VzkwczUjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='3.2'>3.2. Correlation matrix</a>"
      ],
      "metadata": {
        "_uuid": "82a7617e37906622dbe00a1783a13cbf382d2513",
        "id": "744KVWcXzUjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation\n",
        "correlation = telcom.corr()\n",
        "#tick labels\n",
        "matrix_cols = correlation.columns.tolist()\n",
        "#convert to array\n",
        "corr_array = np.array(correlation)\n",
        "\n",
        "#Plotting\n",
        "trace = go.Heatmap(z = corr_array,\n",
        "                   x = matrix_cols,\n",
        "                   y = matrix_cols,\n",
        "                   colorscale = \"Viridis\",\n",
        "                   colorbar = dict(title = \"Pearson Correlation coefficients\", titleside = \"right\"),\n",
        "                  )\n",
        "layout = go.Layout(dict(title = \"Correlation matrix\",\n",
        "                        autosize = False,\n",
        "                        height = 720,\n",
        "                        width = 800,\n",
        "                        margin = dict(r = 0, l = 210, t = 25, b = 210),\n",
        "                        yaxis = dict(tickfont = dict(size = 9)),\n",
        "                        xaxis = dict(tickfont = dict(size = 9))\n",
        "                       )\n",
        "                  )\n",
        "data = [trace]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ],
      "metadata": {
        "_uuid": "b52cf9c7f402ed706e82221e3f8601fdeea9ab27",
        "trusted": true,
        "id": "V-dtqFFpzUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='3.3'>3.3. Visualizing data with principal components</a>"
      ],
      "metadata": {
        "_uuid": "abaf205d4be08b2b9951b1c1a878c6e387998abc",
        "id": "IwFwcSRszUjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_scatter(pcadf, targetfeature, targetlabel, color):\n",
        "    tracer = go.Scatter(x = pcadf[pcadf[targetfeature]==targetlabel][\"PC1\"],\n",
        "                        y = pcadf[pcadf[targetfeature]==targetlabel][\"PC2\"],\n",
        "                        name = targetlabel, mode = \"markers\",\n",
        "                        marker = dict(color = color, line = dict(width = .5), symbol = \"diamond-open\"),\n",
        "                       )\n",
        "    return tracer"
      ],
      "metadata": {
        "trusted": true,
        "id": "hJoVeL6SzUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "\n",
        "X = telcom[[i for i in telcom.columns if i not in target_col]]\n",
        "Y = telcom[target_col]\n",
        "\n",
        "principal_components = pca.fit_transform(X)\n",
        "pca_data = pd.DataFrame(principal_components, columns = [\"PC1\", \"PC2\"])\n",
        "pca_data = pca_data.merge(Y, left_index=True, right_index=True, how=\"left\")\n",
        "pca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1: \"Churn\", 0: \"Not churn\"})\n",
        "\n",
        "layout = go.Layout(dict(title = \"Visualizing data with PCA\",\n",
        "                        plot_bgcolor = \"rgb(243,243,243)\",\n",
        "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
        "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     title = \"first principal component (PC1)\",\n",
        "                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n",
        "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     title = \"second principal component (PC2)\",\n",
        "                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n",
        "                        height = 400\n",
        "                       )\n",
        "                  )\n",
        "trace1 = pca_scatter(pca_data, 'Churn', 'Churn', 'red')\n",
        "trace2 = pca_scatter(pca_data, 'Churn', 'Not churn', 'royalblue')\n",
        "data = [trace2, trace1]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ],
      "metadata": {
        "_uuid": "60c93b7dc48f91fa850d163486f771072f506401",
        "trusted": true,
        "id": "uv4AH-lGzUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='3.4'>3.4. Binary variable distribution in customer churn (Radar Chart)</a>"
      ],
      "metadata": {
        "_uuid": "a261b0d62fe4af69dc412143d6b4e019cd65963e",
        "id": "hDfyFlF7zUjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_radar(df, aggregate, title):\n",
        "    data_frame = df[df[\"Churn\"] == aggregate]\n",
        "    data_frame_x = data_frame[bi_cs].sum().reset_index()\n",
        "    data_frame_x.columns = [\"feature\", \"yes\"]\n",
        "    data_frame_x[\"no\"] = data_frame.shape[0] - data_frame_x[\"yes\"]\n",
        "    data_frame_x = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n",
        "\n",
        "    #count of 1's (yes)\n",
        "    trace1 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(),\n",
        "                             theta = data_frame_x[\"feature\"].tolist(),\n",
        "                             fill = \"toself\",\n",
        "                             name = \"count of 1's\",\n",
        "                             mode = \"markers+lines\",\n",
        "                             marker = dict(size = 5)\n",
        "                            )\n",
        "    #count of 0's (no)\n",
        "    trace2 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n",
        "                             theta = data_frame_x[\"feature\"].tolist(),\n",
        "                             fill = \"toself\",\n",
        "                             name = \"count of 0's\",\n",
        "                             mode = \"markers+lines\",\n",
        "                             marker = dict(size = 5)\n",
        "                            )\n",
        "    layout = go.Layout(dict(polar = dict(radialaxis = dict(visible = True,\n",
        "                                                           side = \"counterclockwise\",\n",
        "                                                           showline = True,\n",
        "                                                           linewidth = 2,\n",
        "                                                           tickwidth = 2,\n",
        "                                                           gridcolor = \"white\",\n",
        "                                                           gridwidth = 2),\n",
        "                                         angularaxis = dict(tickfont = dict(size = 10),\n",
        "                                                            layer = \"below traces\"\n",
        "                                                           ),\n",
        "                                         bgcolor = \"rgb(243,243,243)\",\n",
        "                                        ),\n",
        "                            paper_bgcolor = \"rgb(243,243,243)\",\n",
        "                            title = title, height = 600, width = 600))\n",
        "\n",
        "    data = [trace2, trace1]\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    py.iplot(fig)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Zm65W7u5zUjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separating binary columns\n",
        "bi_cs = telcom.nunique()[telcom.nunique() == 2].keys()\n",
        "dat_rad = telcom[bi_cs]\n",
        "\n",
        "#plotting radar chart for churn and not churn customers (binary variables)\n",
        "plot_radar(dat_rad, 1, \"Churn customers\")\n",
        "plot_radar(dat_rad, 0, \"Not churn customers\")"
      ],
      "metadata": {
        "_uuid": "3a5c9e2edb9121a8db7e2b2d3f1ed23fc9983e9a",
        "trusted": true,
        "id": "xXHDrssPzUjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a id='4'>4. Model Building</a>"
      ],
      "metadata": {
        "_uuid": "f944336cbe67efb3422b79864d9478e2cfbdc860",
        "id": "2UdVFkw2zUjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def telecom_churn_prediction(algorithm, training_x, testing_x, training_y, testing_y, cf, threshold_plot):\n",
        "    #model\n",
        "    algorithm.fit(training_x, training_y)\n",
        "    predictions = algorithm.predict(testing_x)\n",
        "    probabilities = algorithm.predict_proba(testing_x)\n",
        "\n",
        "    print('Algorithm:', type(algorithm).__name__)\n",
        "    print(\"\\nClassification report:\\n\", classification_report(testing_y, predictions))\n",
        "    print(\"Accuracy Score:\", accuracy_score(testing_y, predictions))\n",
        "\n",
        "    #confusion matrix\n",
        "    conf_matrix = confusion_matrix(testing_y, predictions)\n",
        "    #roc_auc_score\n",
        "    model_roc_auc = roc_auc_score(testing_y, predictions)\n",
        "    print(\"Area under curve:\", model_roc_auc,\"\\n\")\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(testing_y, probabilities[:,1])\n",
        "\n",
        "    #plot confusion matrix\n",
        "    trace1 = go.Heatmap(z = conf_matrix,\n",
        "                        x = [\"Not churn\", \"Churn\"],\n",
        "                        y = [\"Not churn\", \"Churn\"],\n",
        "                        showscale = False, colorscale = \"Picnic\",\n",
        "                        name = \"Confusion matrix\")\n",
        "\n",
        "    #plot roc curve\n",
        "    trace2 = go.Scatter(x = fpr, y = tpr,\n",
        "                        name = \"Roc: \" + str(model_roc_auc),\n",
        "                        line = dict(color = ('rgb(22, 96, 167)'), width = 2))\n",
        "    trace3 = go.Scatter(x = [0,1], y = [0,1],\n",
        "                        line = dict(color = ('rgb(205, 12, 24)'), width = 2,\n",
        "                        dash = 'dot'))\n",
        "\n",
        "    if cf in ['coefficients', 'features']:\n",
        "        if cf == 'coefficients':\n",
        "            coefficients = pd.DataFrame(algorithm.coef_.ravel())\n",
        "        elif cf == 'features':\n",
        "            coefficients = pd.DataFrame(algorithm.feature_importances_)\n",
        "\n",
        "        column_df = pd.DataFrame(training_x.columns.tolist())\n",
        "        coef_sumry = (pd.merge(coefficients, column_df, left_index=True,\n",
        "                               right_index=True, how=\"left\"))\n",
        "        coef_sumry.columns = [\"coefficients\", \"features\"]\n",
        "        coef_sumry = coef_sumry.sort_values(by = \"coefficients\", ascending=False)\n",
        "\n",
        "        #plot coeffs\n",
        "        trace4 = go.Bar(x = coef_sumry[\"features\"], y = coef_sumry[\"coefficients\"],\n",
        "                        name = \"coefficients\",\n",
        "                        marker = dict(color = coef_sumry[\"coefficients\"],\n",
        "                                      colorscale = \"Picnic\",\n",
        "                                      line = dict(width = .6, color = \"black\")\n",
        "                                     )\n",
        "                       )\n",
        "        #subplots\n",
        "        fig = make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
        "                                subplot_titles=('Confusion matrix',\n",
        "                                                'Receiver operating characteristic',\n",
        "                                                'Feature importances')\n",
        "                           )\n",
        "        fig.append_trace(trace1,1,1)\n",
        "        fig.append_trace(trace2,1,2)\n",
        "        fig.append_trace(trace3,1,2)\n",
        "        fig.append_trace(trace4,2,1)\n",
        "        fig['layout'].update(showlegend=False, title=\"Model performance\",\n",
        "                             autosize=False, height = 900, width = 800,\n",
        "                             plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
        "                             paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
        "                             margin = dict(b = 195))\n",
        "        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
        "        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
        "        fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True, tickfont = dict(size = 10), tickangle = 90))\n",
        "\n",
        "    elif cf == 'None':\n",
        "        #subplots\n",
        "        fig = make_subplots(rows=1, cols=2,\n",
        "                            subplot_titles=('Confusion matrix',\n",
        "                                            'Receiver operating characteristic')\n",
        "                           )\n",
        "        fig.append_trace(trace1,1,1)\n",
        "        fig.append_trace(trace2,1,2)\n",
        "        fig.append_trace(trace3,1,2)\n",
        "        fig['layout'].update(showlegend=False, title=\"Model performance\",\n",
        "                         autosize=False, height = 500, width = 800,\n",
        "                         plot_bgcolor = 'rgba(240,240,240,0.95)',\n",
        "                         paper_bgcolor = 'rgba(240,240,240,0.95)',\n",
        "                         margin = dict(b = 195))\n",
        "        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
        "        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
        "\n",
        "    py.iplot(fig)\n",
        "\n",
        "    if threshold_plot == True:\n",
        "        visualizer = DiscriminationThreshold(algorithm)\n",
        "        visualizer.fit(training_x,training_y)\n",
        "        visualizer.poof()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kGHOkD52zUjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve,scorer, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from yellowbrick.classifier import DiscriminationThreshold\n",
        "\n",
        "#defining the studied or used independent features (columns) as well the target\n",
        "cols = [i for i in telcom.columns if i not in target_col]\n",
        "target_col = ['Churn']\n",
        "\n",
        "#splitting the principal training dataset to subtrain and subtest datasets\n",
        "x_train, x_test, y_train, y_test = train_test_split(telcom[cols], telcom[target_col],\n",
        "                                                    test_size = .25, random_state = 111)\n",
        "\n",
        "#splitting the no scaled principal training dataset to subtrain and subtest datasets\n",
        "x_train_og, x_test_og, y_train_og, y_test_og = train_test_split(df_telcom_og[cols], telcom[target_col],\n",
        "                                                                test_size = .25, random_state = 111)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7cgvCBYGzUjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.1'>4.1. Baseline model</a>"
      ],
      "metadata": {
        "id": "uWP6TbI3zUjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Baseline model\n",
        "logit = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "                           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "                           verbose=0, warm_start=False)\n",
        "\n",
        "telecom_churn_prediction(logit, x_train, x_test, y_train, y_test, \"coefficients\", threshold_plot=True)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_uuid": "84038088d314f275c654021432f614ecf0b7914d",
        "trusted": true,
        "id": "ZoFY9enIzUjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.2'>4.2. Synthetic Minority Oversampling TEchnique (SMOTE)</a>\n"
      ],
      "metadata": {
        "_uuid": "5d772699a8637e6e9e1a90f424db967b6ae3c12a",
        "id": "FFBHS8pOzUjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#oversampling minority class using smote\n",
        "smote = SMOTE(random_state = 0)\n",
        "x_smote, y_smote = smote.fit_sample(x_train, y_train)\n",
        "x_smote = pd.DataFrame(data = x_smote, columns=cols)\n",
        "y_smote = pd.DataFrame(data = y_smote, columns=target_col)\n",
        "\n",
        "logit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                                 intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "                                 penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "                                 verbose=0, warm_start=False)\n",
        "\n",
        "telecom_churn_prediction(logit_smote, x_smote, x_test, y_smote, y_test, \"coefficients\", threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "977d0eb5f44d745d2e54b9643df9c3bcf5d461f7",
        "trusted": true,
        "id": "BAevyQBWzUjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.3'>4.3. Recursive Feature Elimination</a>\n",
        "Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."
      ],
      "metadata": {
        "_uuid": "35f4bbedca5efb1ea70dfa71649cf36e5bdd6e86",
        "id": "es9y-V1uzUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "logit_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                               intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "                               penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "                               verbose=0, warm_start=False)\n",
        "\n",
        "\n",
        "rfe = RFE(logit_rfe, 10)\n",
        "rfe = rfe.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "#identified columns Recursive Feature Elimination\n",
        "idc_rfe = pd.DataFrame({\"rfe_support\": rfe.support_,\n",
        "                        \"columns\": cols,\n",
        "                        \"ranking\": rfe.ranking_,\n",
        "                       })\n",
        "cols_rfe = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n",
        "\n",
        "#applying model\n",
        "telecom_churn_prediction(logit_rfe, x_train[cols_rfe], x_test[cols_rfe], y_train, y_test, \"coefficients\", threshold_plot=True)\n",
        "\n",
        "table_rk = ff.create_table(idc_rfe)\n",
        "py.iplot(table_rk)"
      ],
      "metadata": {
        "_uuid": "a12d867c80eb421a8f97edc35417c53fef9243ed",
        "trusted": true,
        "id": "w1ANd7oszUjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.4'>4.4. Univariate Selection</a>\n",
        "* Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
        "* uses the chi squared ($\\chi^2$) statistical test for non-negative features to select the best features"
      ],
      "metadata": {
        "_uuid": "1f7057d8314e17bf67c544794a6b3c2025ac9b99",
        "id": "TejdSBaezUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "#dataframe with non negative values\n",
        "x_df = df_telcom_og[cols]\n",
        "y_df = df_telcom_og[target_col]\n",
        "\n",
        "#fit model with k= 3\n",
        "select = SelectKBest(score_func = chi2, k = 3)\n",
        "select = select.fit(x_df, y_df)\n",
        "\n",
        "#create dataframe\n",
        "score = pd.DataFrame({\"features\": cols, \"scores\": select.scores_, \"p_values\": select.pvalues_ })\n",
        "score = score.sort_values(by = \"scores\", ascending=False)\n",
        "\n",
        "#createing new label for categorical and numerical columns\n",
        "score[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols), \"Numerical\", \"Categorical\")\n",
        "\n",
        "table_score = ff.create_table(score)\n",
        "py.iplot(table_score)\n",
        "\n",
        "#plot\n",
        "trace1 = go.Scatter(x = score[score[\"feature_type\"]==\"Categorical\"][\"features\"],\n",
        "                   y = score[score[\"feature_type\"]==\"Categorical\"][\"scores\"],\n",
        "                   name = \"Categorial\", mode = \"lines+markers\",\n",
        "                   marker = dict(color = \"red\", line = dict(width =1))\n",
        "                   )\n",
        "\n",
        "trace2 = go.Bar(x = score[score[\"feature_type\"]==\"Numerical\"][\"features\"],\n",
        "                y = score[score[\"feature_type\"]==\"Numerical\"][\"scores\"], name = \"Numerical\",\n",
        "                marker = dict(color = \"royalblue\", line = dict(width =1)),\n",
        "                xaxis = \"x2\", yaxis = \"y2\"\n",
        "               )\n",
        "layout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n",
        "                        plot_bgcolor = \"rgb(243,243,243)\",\n",
        "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
        "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     tickfont = dict(size =10),\n",
        "                                     domain=[0, 0.7],\n",
        "                                     tickangle = 90, zerolinewidth=1,\n",
        "                                     ticklen=5, gridwidth=2),\n",
        "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     title = \"scores\",\n",
        "                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n",
        "                        margin = dict(b=200),\n",
        "                        xaxis2=dict(domain=[0.8, 1], tickangle = 90, gridcolor = 'rgb(255, 255, 255)'),\n",
        "                        yaxis2=dict(anchor='x2', gridcolor = 'rgb(255, 255, 255)')\n",
        "                        )\n",
        "                  )\n",
        "\n",
        "data = [trace1, trace2]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ],
      "metadata": {
        "_uuid": "27089924eba9425a075576c5254523281dc5b1f5",
        "trusted": true,
        "id": "fBsrJ3OazUjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.5'>4.5. Decision Tree Classifier</a>\n"
      ],
      "metadata": {
        "_uuid": "a07fecf352ce39ca7cc43664b6995807a89a3821",
        "id": "oS6nfNWIzUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def treeplot(classifier, cols, classnames):\n",
        "    #plot decision tree\n",
        "    graph = Source(tree.export_graphviz(classifier, out_file=None,\n",
        "                                        rounded=True, proportion=False,\n",
        "                                        feature_names = cols,\n",
        "                                        precision = 2,\n",
        "                                        class_names = classnames,\n",
        "                                        filled = True)\n",
        "                  )\n",
        "    display(graph)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wgllYePJzUjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from graphviz import Source\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(max_depth = 9, random_state = 123,\n",
        "                                       splitter = \"best\", criterion = \"gini\")\n",
        "\n",
        "telecom_churn_prediction(decision_tree, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)\n",
        "\n",
        "#plot decision tree\n",
        "treeplot(decision_tree, cols, [\"Not churn\", \"Churn\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "fvTkXhLNzUjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.6'>4.6. KNN Classifier</a>\n"
      ],
      "metadata": {
        "_uuid": "d1f760b002defd916b4566ae59312bcada1a9229",
        "id": "kzDm-FkdzUjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
        "                           weights='uniform')\n",
        "telecom_churn_prediction(knn, x_train, x_test, y_train, y_test, 'None', threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "8697d16c7e56db13e012458c797b60c3fa6b2f67",
        "trusted": true,
        "id": "XFcTZmolzUjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.7'>4.7. Random Forest Classifier</a>\n",
        "Random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement."
      ],
      "metadata": {
        "_uuid": "5dac202bbbe6e6869eab168e6a10a1efa6abe291",
        "id": "OaKrVvMHzUjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators = 100, random_state = 123,\n",
        "                             max_depth = 9, criterion = \"gini\")\n",
        "\n",
        "telecom_churn_prediction(rfc, x_train, x_test, y_train, y_test, 'features', threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GncgkXZbzUjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.8'>4.8. Gaussian Naive Bayes</a>"
      ],
      "metadata": {
        "_uuid": "d89e418310cb3f60d4db4fdb4be330a74b918ba7",
        "id": "VQZUzylOzUjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB(priors=None)\n",
        "\n",
        "telecom_churn_prediction(gnb, x_train, x_test, y_train, y_test, 'None', threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "106512611d7108e63d5b4dc38cdf5fd72eef8ea4",
        "trusted": true,
        "id": "8zkhyCMJzUjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.9'>4.9. Support Vector Machine</a>\n",
        "“Support Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges.   it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space .where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes.\n",
        "\n",
        "### <a id='4.9.1'>4.9.1. Support Vector Machine (linear)</a>"
      ],
      "metadata": {
        "_uuid": "6574aaec38141dce75510e2b473058238711e74d",
        "id": "_SUlohevzUjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "#Support vector classifier using linear hyper plane\n",
        "svc_lin  = SVC(C=1.0, kernel='linear', probability=True, random_state=124)\n",
        "\n",
        "telecom_churn_prediction(svc_lin, x_train, x_test, y_train, y_test, \"coefficients\", threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "5c44767e6467369ffd0bbe77bf74cc2af6d66455",
        "trusted": true,
        "id": "BSAUTveVzUjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a id='4.9.2'>4.9.2. Support Vector Machine (rbf)</a>"
      ],
      "metadata": {
        "id": "Ok0aXo-uzUjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#support vector classifier using non-linear hyper plane (\"rbf\")\n",
        "svc_rbf  = SVC(C=10.0, kernel='rbf', gamma=0.1, probability=True, random_state=124)\n",
        "\n",
        "telecom_churn_prediction(svc_rbf, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2bNMdsiszUjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.10'>4.10. LightGBM Classifier</a>"
      ],
      "metadata": {
        "_uuid": "940f332d9d6c261cda8e149c634e2526b591c88b",
        "id": "kVr9bWF-zUjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbmc = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
        "                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n",
        "                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
        "                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n",
        "                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
        "                        subsample_for_bin=200000, subsample_freq=0)\n",
        "\n",
        "telecom_churn_prediction(lgbmc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "c76c25d63a9554b5d20ae9be3cff0069dabdede8",
        "trusted": true,
        "id": "wKMkbeQQzUjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.11'>4.11. XGBoost  Classifier</a>"
      ],
      "metadata": {
        "_uuid": "ce2c26ca71afd0cb5be5428fc467ab6ccadfc78c",
        "id": "YJwvvlZDzUjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n",
        "                    max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n",
        "                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
        "                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "                    silent=True, subsample=1)\n",
        "\n",
        "telecom_churn_prediction(xgc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)"
      ],
      "metadata": {
        "_uuid": "23bd0fd13e72af0845582cca9376fb1ef658c0d7",
        "trusted": true,
        "id": "3zH5snnzzUjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.12'>4.12. Gaussian Process Classifier</a>"
      ],
      "metadata": {
        "id": "pNeNE28FzUjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "gpc = GaussianProcessClassifier(random_state=124)\n",
        "\n",
        "telecom_churn_prediction(gpc, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4wLUiahIzUjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.13'>4.13. AdaBoost Classifier</a>"
      ],
      "metadata": {
        "id": "DQut4RNdzUjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "adac = AdaBoostClassifier(random_state=124)\n",
        "\n",
        "telecom_churn_prediction(adac, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JvefUgxLzUjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.14'>4.14. GradientBoosting Classifier</a>"
      ],
      "metadata": {
        "id": "bEX7LS6szUjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gbc = GradientBoostingClassifier(random_state=124)\n",
        "\n",
        "telecom_churn_prediction(gbc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SMIzo57gzUjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.15'>4.15. Linear Discriminant Analysis</a>"
      ],
      "metadata": {
        "id": "CJ9iahzDzUjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "telecom_churn_prediction(lda, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Er_5pmTGzUja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.15'>4.16. Quadratic Discriminant Analysis</a>"
      ],
      "metadata": {
        "id": "fyiUi_SczUja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "telecom_churn_prediction(qda, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JPCnpA2yzUja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.17'>4.17. Multi-layer Perceptron Classifier</a>"
      ],
      "metadata": {
        "id": "f38uBIqCzUja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(alpha=1, max_iter=1000, random_state=124)\n",
        "\n",
        "telecom_churn_prediction(mlp, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-oIpNmQxzUja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='4.18'>4.18. Bagging Classifier</a>"
      ],
      "metadata": {
        "id": "gEEvC4xuzUjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble.bagging import BaggingClassifier\n",
        "\n",
        "bgc = BaggingClassifier(random_state=124)\n",
        "\n",
        "telecom_churn_prediction(bgc, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IJWEM1OlzUjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a id='5'>5. Model performances over the training dataset</a>"
      ],
      "metadata": {
        "_uuid": "f985c3fb0797143d22aa5635cb58cbbab954bb2c",
        "id": "lonfuu8CzUjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#putting all the model names, model classes and the used columns in a dictionary\n",
        "models = {'Logistic (Baseline)': [logit, cols],\n",
        "          'Logistic (SMOTE)': [logit_smote, cols],\n",
        "          'Logistic (RFE)': [logit_rfe, cols_rfe],\n",
        "          'Decision Tree': [decision_tree, cols],\n",
        "          'KNN Classifier': [knn, cols],\n",
        "          'Random Forest': [rfc, cols],\n",
        "          'Naive Bayes': [gnb, cols],\n",
        "          'SVM (linear)': [svc_lin, cols],\n",
        "          'SVM (rbf)': [svc_rbf, cols],\n",
        "          'LGBM Classifier': [lgbmc, cols],\n",
        "          'XGBoost Classifier': [xgc, cols],\n",
        "          'Gaussian Process': [gpc, cols],\n",
        "          'AdaBoost': [adac, cols],\n",
        "          'GradientBoost': [gbc, cols],\n",
        "          'LDA': [lda, cols],\n",
        "          'QDA': [qda, cols],\n",
        "          'MLP Classifier': [mlp, cols],\n",
        "          'Bagging Classifier': [bgc, cols],\n",
        "         }"
      ],
      "metadata": {
        "trusted": true,
        "id": "IgOa8STbzUjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='5.1'>5.1. Model performance metrics</a>"
      ],
      "metadata": {
        "id": "PYkqMAvWzUjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gives model report in dataframe\n",
        "def model_report(model, training_x, testing_x, training_y, testing_y, name):\n",
        "    model = model.fit(training_x, training_y)\n",
        "    predictions = model.predict(testing_x)\n",
        "    accuracy = accuracy_score(testing_y, predictions)\n",
        "    recallscore = recall_score(testing_y, predictions)\n",
        "    precision = precision_score(testing_y, predictions)\n",
        "    roc_auc = roc_auc_score(testing_y, predictions)\n",
        "    f1score = f1_score(testing_y, predictions)\n",
        "    kappa_metric = cohen_kappa_score(testing_y, predictions)\n",
        "\n",
        "    df = pd.DataFrame({\"Model\"           : [name],\n",
        "                       \"Accuracy\"        : [accuracy],\n",
        "                       \"Recall\"          : [recallscore],\n",
        "                       \"Precision\"       : [precision],\n",
        "                       \"f1-score\"        : [f1score],\n",
        "                       \"Roc_auc\"         : [roc_auc],\n",
        "                       \"Kappa_metric\"    : [kappa_metric],\n",
        "                      })\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "id": "sBW5nQhVzUjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outputs for all models over the training dataset\n",
        "model_performances_train = pd.DataFrame()\n",
        "for name in models:\n",
        "    if name == 'Logistic (SMOTE)':\n",
        "        model_performances_train = model_performances_train.append(model_report(models[name][0],\n",
        "                                                                                x_smote[models[name][1]], x_test[models[name][1]],\n",
        "                                                                                y_smote, y_test, name), ignore_index=True)\n",
        "    else:\n",
        "        model_performances_train = model_performances_train.append(model_report(models[name][0], x_train[models[name][1]],\n",
        "                                                                                x_test[models[name][1]],\n",
        "                                                                                y_train, y_test, name), ignore_index=True)\n",
        "\n",
        "table_train = ff.create_table(np.round(model_performances_train, 4))\n",
        "py.iplot(table_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jTeZFRlRzUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='5.2'>5.2. Compare model metrics</a>"
      ],
      "metadata": {
        "_uuid": "132cc1f1657a71dd267b44c232741b44b5f174fb",
        "id": "qkV5gRd1zUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_tracer(df, metric, color):\n",
        "    tracer = go.Bar(y = df[\"Model\"],\n",
        "                    x = df[metric],\n",
        "                    orientation = \"h\", name = metric ,\n",
        "                    marker = dict(line = dict(width =.7), color = color)\n",
        "                   )\n",
        "    return tracer\n",
        "\n",
        "def modelmetricsplot(df, title):\n",
        "    layout = go.Layout(dict(title = title,\n",
        "                        plot_bgcolor = \"rgb(243,243,243)\",\n",
        "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
        "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     title = \"metric\",\n",
        "                                     zerolinewidth=1,\n",
        "                                     ticklen=5, gridwidth=2),\n",
        "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
        "                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n",
        "                        margin = dict(l = 250),\n",
        "                        height = 780\n",
        "                       )\n",
        "                  )\n",
        "    trace1 = output_tracer(df, \"Accuracy\", \"#6699FF\")\n",
        "    trace2 = output_tracer(df, 'Recall', \"red\")\n",
        "    trace3 = output_tracer(df, 'Precision', \"#33CC99\")\n",
        "    trace4 = output_tracer(df, 'f1-score', \"lightgrey\")\n",
        "    trace5 = output_tracer(df, 'Roc_auc', \"magenta\")\n",
        "    trace6 = output_tracer(df, 'Kappa_metric', \"#FFCC99\")\n",
        "\n",
        "    data = [trace1, trace2, trace3, trace4, trace5, trace6]\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    py.iplot(fig)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SjbqjYPFzUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelmetricsplot(df=model_performances_train, title=\"Model performances over the training dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fUqHAOZYzUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='5.3'>5.3. Confusion matrices for models</a>"
      ],
      "metadata": {
        "_uuid": "920f02fd2a3da5aed679aade56b1227481cc42a3",
        "id": "3mRAbYPxzUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confmatplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n",
        "    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n",
        "    fig.set_facecolor(\"#F3F3F3\")\n",
        "    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n",
        "        plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n",
        "        if name=='Logistic (SMOTE)':\n",
        "            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "            conf_matrix = confusion_matrix(target_test, predictions)\n",
        "            sns.heatmap(conf_matrix, annot=True, fmt = \"d\", square = True,\n",
        "                        xticklabels=[\"Not churn\", \"Churn\"],\n",
        "                        yticklabels=[\"Not churn\", \"Churn\"],\n",
        "                        linewidths = 2, linecolor = \"w\", cmap = \"Set1\")\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.subplots_adjust(wspace = .3, hspace = .3)\n",
        "        else:\n",
        "            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "            conf_matrix = confusion_matrix(target_test, predictions)\n",
        "            sns.heatmap(conf_matrix, annot=True, fmt = \"d\", square = True,\n",
        "                        xticklabels=[\"Not churn\", \"Churn\"],\n",
        "                        yticklabels=[\"Not churn\", \"Churn\"],\n",
        "                        linewidths = 2, linecolor = \"w\", cmap = \"Set1\")\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.subplots_adjust(wspace = .3, hspace = .3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Xr93suf7zUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmatplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test,\n",
        "             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dix7xQ14zUjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='5.4'>5.4. ROC - Curves  for models</a>"
      ],
      "metadata": {
        "_uuid": "7d3d15f7aa0c14639397d99ac351be0324605ff9",
        "id": "8UZe3mDjzUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rocplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n",
        "    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n",
        "    fig.set_facecolor(\"#F3F3F3\")\n",
        "    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n",
        "        qx = plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n",
        "        if name=='Logistic (SMOTE)':\n",
        "            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n",
        "            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "\n",
        "            fpr, tpr, thresholds = roc_curve(target_test, probabilities[:,1])\n",
        "            plt.plot(fpr, tpr, linestyle = \"dotted\",\n",
        "                     color = \"royalblue\", linewidth = 2,\n",
        "                     label = \"AUC = \" + str(np.around(roc_auc_score(target_test, predictions), 3)))\n",
        "            plt.plot([0,1],[0,1], linestyle = \"dashed\",\n",
        "                     color = \"orangered\", linewidth = 1.5)\n",
        "            plt.fill_between(fpr, tpr, alpha = .1)\n",
        "            plt.fill_between([0, 1], [0, 1], color = \"b\")\n",
        "            plt.legend(loc = \"lower right\",\n",
        "                       prop = {\"size\" : 12})\n",
        "            qx.set_facecolor(\"w\")\n",
        "            plt.grid(True, alpha = .15)\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.xticks(np.arange(0, 1, .3))\n",
        "            plt.yticks(np.arange(0, 1, .3))\n",
        "\n",
        "        else:\n",
        "            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n",
        "            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "\n",
        "            fpr, tpr, thresholds = roc_curve(target_test, probabilities[:,1])\n",
        "            plt.plot(fpr, tpr, linestyle = \"dotted\",\n",
        "                     color = \"royalblue\", linewidth = 2,\n",
        "                     label = \"AUC = \" + str(np.around(roc_auc_score(target_test, predictions), 3)))\n",
        "            plt.plot([0,1],[0,1], linestyle = \"dashed\",\n",
        "                     color = \"orangered\", linewidth = 1.5)\n",
        "            plt.fill_between(fpr, tpr, alpha = .1)\n",
        "            plt.fill_between([0, 1], [0, 1], color = \"b\")\n",
        "            plt.legend(loc = \"lower right\",\n",
        "                       prop = {\"size\" : 12})\n",
        "            qx.set_facecolor(\"w\")\n",
        "            plt.grid(True, alpha = .15)\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.xticks(np.arange(0, 1, .3))\n",
        "            plt.yticks(np.arange(0, 1, .3))"
      ],
      "metadata": {
        "trusted": true,
        "id": "XtNSB6fezUjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rocplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test,\n",
        "             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xhsSXdIxzUjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='5.5'>5.5. Precision recall curves</a>"
      ],
      "metadata": {
        "_uuid": "4e3e5dd305ef65d9c16be5a93634689ce944de5a",
        "id": "WAInhmiTzUjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prcplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n",
        "    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n",
        "    fig.set_facecolor(\"#F3F3F3\")\n",
        "    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n",
        "        qx = plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n",
        "        if name=='Logistic (SMOTE)':\n",
        "            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n",
        "            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "\n",
        "            recall, precision, thresholds = precision_recall_curve(target_test, probabilities[:,1])\n",
        "            plt.plot(recall, precision, linewidth = 1.5,\n",
        "                     label = (\"avg_pcn: \"+str(np.around(average_precision_score(target_test, predictions), 3))))\n",
        "            plt.plot([0, 1], [0, 0], linestyle = \"dashed\")\n",
        "            plt.fill_between(recall, precision, alpha = .1)\n",
        "            plt.legend(loc = \"lower left\", prop = {\"size\": 10})\n",
        "            qx.set_facecolor(\"w\")\n",
        "            plt.grid(True, alpha = .15)\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.xlabel(\"recall\", fontsize=7)\n",
        "            plt.ylabel(\"precision\", fontsize=7)\n",
        "            plt.xlim([0.25,1])\n",
        "            plt.yticks(np.arange(0, 1, .3))\n",
        "        else:\n",
        "            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n",
        "            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n",
        "            predictions = model.predict(df_test[modeldict[name][1]])\n",
        "\n",
        "            recall, precision, thresholds = precision_recall_curve(target_test, probabilities[:,1])\n",
        "            plt.plot(recall, precision, linewidth = 1.5,\n",
        "                     label = (\"avg_pcn: \"+str(np.around(average_precision_score(target_test, predictions), 3))))\n",
        "            plt.plot([0, 1], [0, 0], linestyle = \"dashed\")\n",
        "            plt.fill_between(recall, precision, alpha = .1)\n",
        "            plt.legend(loc = \"lower left\", prop = {\"size\": 10})\n",
        "            qx.set_facecolor(\"w\")\n",
        "            plt.grid(True, alpha = .15)\n",
        "            plt.title(name, color = \"b\")\n",
        "            plt.xlabel(\"recall\", fontsize=7)\n",
        "            plt.ylabel(\"precision\", fontsize=7)\n",
        "            plt.xlim([0.25,1])\n",
        "            plt.yticks(np.arange(0, 1, .3))"
      ],
      "metadata": {
        "trusted": true,
        "id": "BHZvn1S_zUjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prcplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test,\n",
        "             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wiLV3_f0zUjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a id='6'>6. Model performances over the principal test dataset</a>\n",
        "## <a id='6.1'>6.1. Model performance metrics</a>"
      ],
      "metadata": {
        "id": "SkaN_KwkzUjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#outputs for all models over the principal test dataset\n",
        "model_performances_test = pd.DataFrame()\n",
        "for name in models:\n",
        "    if name == 'Logistic (SMOTE)':\n",
        "        model_performances_test = model_performances_test.append(model_report(models[name][0],\n",
        "                                                                              x_smote[models[name][1]], telcom_test[models[name][1]],\n",
        "                                                                              y_smote, telcom_test[target_col], name), ignore_index=True)\n",
        "    else:\n",
        "        model_performances_test = model_performances_test.append(model_report(models[name][0],\n",
        "                                                                              x_train[models[name][1]], telcom_test[models[name][1]],\n",
        "                                                                              y_train, telcom_test[target_col], name), ignore_index=True)\n",
        "\n",
        "table_test = ff.create_table(np.round(model_performances_test, 4))\n",
        "py.iplot(table_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "G9KdtYiTzUjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='6.2'>6.2. Compare model metrics</a>"
      ],
      "metadata": {
        "id": "bWJaLVXVzUje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelmetricsplot(df=model_performances_test, title=\"Model performances over the principal test dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "e2vXZ4IQzUje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='6.3'>6.3. Confusion matrices for models</a>"
      ],
      "metadata": {
        "id": "GYBjiB6hzUjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confmatplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols],\n",
        "             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6SaoozGFzUjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='6.4'>6.4. ROC - Curves for models</a>"
      ],
      "metadata": {
        "id": "BjaOsaRCzUjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rocplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols],\n",
        "             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_9DS_W2TzUjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a id='6.5'>6.5. Precision recall curves</a>"
      ],
      "metadata": {
        "id": "YdNNynfIzUjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prcplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols],\n",
        "             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KKLDKaxjzUjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}